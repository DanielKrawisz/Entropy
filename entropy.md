# Entropy

## Conceptual Issues

### Irreversibility

Entropy is a theoretical quantity that explains irreversibility in physics. Known laws of physics are reversible, which means some physical process would be equally valid both forwards or backwards in time. (For everyday phsyics, this statement is exactly true, whereas for some processes in high energy physics the time-reversed version of a process would also have to be mirror-image reversed as well in order to be valid.) However, in ordinary experience, many unexceptional processes would be quite exceptional if they were reversed. No one has ever experienced a convergence of sound waves into a puddle of liquid and pieces of glass sufficient to project them into the air and together in his hand as an unbroken cup of hot tea but many people have experienced the time-reversed version of such a process.

Thus, we observe that physics is irreversible on an everday scale but in controlled conditions designed to experiment with fundamental processes, physics is reversible. Intuitively, the resolution of this apparent paradox follows from a statistical understanding of the physics of our everday experience. Not knowing the precise interactions of all particles around us, from our perspective, the evolution of our everyday system needs to be treated as random. The relevant features of our experience do not depend on the exact position of every particle in our environment. Rather, many possible configurations of matter would result in indistinguishable experiences. 

The key to the argument is to note that different configurations of matter might be indistinguishable from vastly different numbers of similar configurations. This would mean that someone who expected his system to evolve randomly would expect some experiences to be vastly more likely than others. A configuration that is similar to fewer others is considered to be low entropy and one that is similar to many others is high entropy. Evolution from low to high entropy is likely, whereas high to low is unlikely. To put it concretely, here are vastly more ways for a tea cup to fall and break and for tea to spill than for tea to be prepared properly. 

### Entropy as Disorder

Entropy is often characterized as an expression of the disorder of a system. This characterization certainly raises more questions than it answers because disorder would seem to be potentially an obscure property of some system. In real life, order can appear superficially to be disorder and vice versa. Therefore, how could we possibly quantify disorder? 

In fact, entropy is not a quantity that can be measured in real systems. It can only be applied objectively to theoretical systems whose nature is given by hypothesis. In a real life system, it would only be with a complete understanding that one could say how disordered it really was. In science we never truly know that we have a complete understanding of anything. Rather, our theories tend to get better over time as more observations and analyses are done. Therefore, any purported expression of the disorder of some real system would have to be understood as a theoretical claim supported by an understanding of the nature of the system in question, which would be the result of analysis, not antecedent to it. 

Thus, I would say that entropy as disorder, though not inaccurate, is quite a confusing soundbyte that requires a lot of context to make sense of, whereas entropy as an explanation for irreversibility more directly approaches the fundamental idea. 

### The Second Law of Thermodynamics

If entropy is not an objective or observable quantity, what of the second law of thermodynamics? This law states

2. **In a closed system, the entropy never decreases.**

How can there be a law about an unobservable theoretical construct? The second law is not a law of physics in the same sense as the law of gravity or even the first law of thermodynamics, which states 

1. **Energy is conserved.** 

These laws can be tested empirically, whereas the second law cannot. 

When entropy was first described, physicists inferred its existence but did not understand what it was. Plank, for example, believed that entropy was a fundamental quantity like energy that would eventually be observed directly. However, he was disappointed when Boltzman was able to explain it as emerging out of statistical mechanics because he wanted to be working on fundamental laws, not emergent quantities. Before Boltzman's work, physicists did not understand entropy as relating to disorder. Instead, entropy was understood as a quantity whose increase expressed irreversibility in physics. 

Thus the second law of thermodynamics, despite being an important principle, is not a real law of physics but was promoted to one due to a mistaken understanding of entropy as an emprical rather than a theoretical concept. The second law of thermodynamics resembles praxeology more than it resembles other laws of physics because they both have to do with laws about ideal things like value that we ascribe to the world but cannot observe. 

## Entropy in Thermodynamics

### Definition of Entropy



### Temperature

When entropy was first proposed, entropy was defined in terms of temperature. Nowadays, temperature is defined in terms of entropy. 

Temperature was originally defined in terms of thermometers in which fluides could be observed to expand and contract in response to hot and cold. Once temperature could be measuered, it became possible to understand heat as a kind of enerrgy and to distinguish between heat and temperature. Formerly, it was assumed that temperature was a measure of the internal heat of a body, but this is not so. Different substances have different heat capacities, which means that different amounts of heat energy can be absorbed or released by them to change their temperatures by the same amount. 

But if temperature is not a measure of heat, what is it measuring? Certain ideal substances could have a formula for temperature asscribed to them. For ideal gasses, temperature is proportional to the average kinetic energy of a particle in the gas. This formula explains the heat capacity of gasses in terms of their molecular composition. In particular, some gasses store potential energy as well as kinetic energy. In general, gasses with more complex molecules will store more average potential energy at equilibrium than gasses with less complex molecules. Even though real gasses are not ideal, the ideal gas analysis explains a great deal about why carbon dioxide is a stronger greenhouse gas than oxygen, and why methane is stronger than carbon dioxide. Stronger greenhouse gasses store more energy at a given temperature than weaker gasses, and are thus at a higher temperature when they radiate the same amount energy into space that they absorb from the sun. 

For more general sysetms, it is hard to define exactly what temperature is measuring. The zeroth law of thermodynamics, which was added later, states 

0. **Bodies of the same temperature are in thermodynamic equilibrium.**

Thus, temperature is measured by allowing a thermometer to come into equilibrium with the substance being tested. At equilibrium, the substance is giving as much energy from its interaction with the thermometer as the thermometer is giving back to it. This information is enough to define 

### Discovery of Entropy


### Laws of Thermodynamics

To reiterate, the laws of thermodynamics are 

0. **Bodies of the same temperature are in thermodynamic equilibrium.**
1. **Energy is conserved.** 
2. **In a closed system, the entropy never decreases.**
3. **As the temperature approaches absolute zero, the entropy approaches a constant value.**

The third law is the one we have not yet exmained, so we will explain it here. 



## Entropy and Life

## Entropy and Quantum Gravity
